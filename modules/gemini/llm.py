import dataclasses
from collections.abc import Iterable
from typing import Callable

from vertexai.generative_models import Content, GenerativeModel

from akari import (
    AkariData,
    AkariDataSet,
    AkariDataSetType,
    AkariLogger,
    AkariModule,
    AkariModuleType,
    AkariRouter,
)

_models: dict[str, GenerativeModel] = {}


@dataclasses.dataclass
class _LLMModuleParams:
    """Defines the necessary parameters for invoking a Google Gemini language model.

    Includes the specific model identifier (e.g., "gemini-pro") and the
    conversation content, which can be provided directly or generated via a function.

    Attributes:
        model (str): The identifier of the Gemini model to be used (e.g.,
            "gemini-pro", "gemini-1.5-flash-latest"). This determines which version of the
            Gemini family will process the request.
        messages (Optional[Iterable[Content]]): A sequence of `Content` objects
            that constitute the conversation history or prompt. This is used if
            `messages_function` is not provided or returns `None`.
        messages_function (Optional[Callable[[AkariData], Iterable[Content]]]):
            A callable that accepts an `AkariData` instance and dynamically
            generates the sequence of `Content` objects for the prompt. This allows
            the conversation to be built based on data from previous steps in an
            Akari pipeline. If provided, it takes precedence. Defaults to `None`.
    """

    model: str
    messages: Iterable[Content] | None = None
    messages_function: Callable[[AkariData], Iterable[Content]] | None = None


class _LLMModule(AkariModule):
    """Provides an interface to Google's Gemini large language models.

    Enables content generation by sending structured conversation history (as a
    sequence of `Content` objects) to a specified Gemini model. It manages a
    local cache of `GenerativeModel` instances to optimize repeated calls to the
    same model.
    """

    def __init__(self, router: AkariRouter, logger: AkariLogger) -> None:
        """Constructs an _LLMModule instance for interacting with Gemini models.

        Args:
            router (AkariRouter): The Akari router instance, used for base module
                initialization.
            logger (AkariLogger): The logger instance for recording operational
                details, debugging information, and API interactions.
        """
        super().__init__(router, logger)

    def call(self, data: AkariData, params: _LLMModuleParams, callback: AkariModuleType | None = None) -> AkariDataSet:
        """Sends a request to the specified Google Gemini model to generate textual content.

        The conversation history (prompt) is determined either from the static
        `params.messages` or dynamically via `params.messages_function`. The module
        uses a shared, in-memory cache (`_models`) to store and reuse initialized
        `GenerativeModel` instances, potentially improving performance for
        subsequent calls to the same model. The generated text from the model's
        response is then packaged into an `AkariDataSet`.

        Args:
            data (AkariData): The input `AkariData` object. This is passed to
                `params.messages_function` if it is set, allowing the prompt to be
                dynamically constructed based on previous pipeline results.
            params (_LLMModuleParams): An object containing the target Gemini model
                name and the conversation content (either directly or via a function).
            callback (Optional[AkariModuleType]): An optional callback module.
                This parameter is currently not used by the Gemini LLMModule.

        Returns:
            AkariDataSet: An `AkariDataSet` where:
                - `text.main` contains the primary textual content generated by the
                  Gemini model.
                - `allData` holds the complete raw response object returned by the
                  `GenerativeModel.generate_content` method.

        Raises:
            ValueError: If `params.messages` is `None` and `params.messages_function`
                is also `None` or returns `None`, meaning no message content is
                available to send to the model.
            GoogleAPIError: If the call to the Gemini API fails due to issues such
                as authentication, network problems, or invalid API usage. (Note:
                Specific exception types may vary based on the `vertexai` library).
        """
        self._logger.debug("LLMModule called")
        self._logger.debug("Data: %s", data)
        self._logger.debug("Params: %s", params)
        self._logger.debug("Callback: %s", callback)

        if params.messages_function is not None:
            params.messages = params.messages_function(data)
        if params.messages is None:
            raise ValueError("Messages cannot be None. Please provide a valid list of messages.")

        if params.model not in _models:
            _models[params.model] = GenerativeModel(params.model)

        model = _models[params.model]
        response = model.generate_content(params.messages)

        dataset = AkariDataSet()
        dataset.text = AkariDataSetType(main=response.text)
        dataset.allData = response
        return dataset
